{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7f950cbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "from mir_eval.separation import bss_eval_sources\n",
    "import soundfile as sf\n",
    "import torch\n",
    "import torchaudio\n",
    "\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class UNet(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, n_class):\n",
    "        super(UNet, self).__init__()\n",
    "\n",
    "        self.conv1 = torch.nn.Conv2d(1, 16, kernel_size=5, stride=2, padding=2)\n",
    "        \n",
    "        self.conv_bn1 = torch.nn.BatchNorm2d(16)\n",
    "        \n",
    "        self.conv2 = torch.nn.Conv2d(16, 32, kernel_size=5, stride=2, padding=2)\n",
    "        \n",
    "        self.conv_bn2 = torch.nn.BatchNorm2d(32)\n",
    "        \n",
    "        self.conv3 = torch.nn.Conv2d(32, 64, kernel_size=5, stride=2, padding=2)\n",
    "        \n",
    "        self.conv_bn3 = torch.nn.BatchNorm2d(64)\n",
    "        \n",
    "        self.conv4 = torch.nn.Conv2d(64, 128, kernel_size=5, stride=2, padding=2)\n",
    "        \n",
    "        self.conv_bn4 = torch.nn.BatchNorm2d(128)\n",
    "        \n",
    "        self.conv5 = torch.nn.Conv2d(128, 256, kernel_size=5, stride=2, padding=2)\n",
    "        \n",
    "        self.conv_bn5 = torch.nn.BatchNorm2d(256)\n",
    "        \n",
    "        self.conv6 = torch.nn.Conv2d(256, 512, kernel_size=5, stride=2, padding=2)\n",
    "        self.conv_bn6 = torch.nn.BatchNorm2d(512)\n",
    "#----------------------------------------------------------------------------------------------------------------\n",
    "        self.deconv1 = torch.nn.ConvTranspose2d(512, 256, kernel_size=5, stride=2, padding=2, output_padding=1)\n",
    "        \n",
    "        self.deconv_bn1 = torch.nn.BatchNorm2d(256)\n",
    "        \n",
    "        self.dropout1 = torch.nn.Dropout2d(0.5)\n",
    "        \n",
    "        self.deconv2 = torch.nn.ConvTranspose2d(512, 128, kernel_size=5, stride=2, padding=2, output_padding=1)\n",
    "        \n",
    "        self.deconv_bn2 = torch.nn.BatchNorm2d(128)\n",
    "        \n",
    "        self.dropout2 = torch.nn.Dropout2d(0.5)\n",
    "        \n",
    "        self.deconv3 = torch.nn.ConvTranspose2d(256, 64, kernel_size=5, stride=2, padding=2, output_padding=1)\n",
    "        \n",
    "        self.deconv_bn3 = torch.nn.BatchNorm2d(64)\n",
    "        \n",
    "        self.dropout3 = torch.nn.Dropout2d(0.5)\n",
    "        \n",
    "        self.deconv4 = torch.nn.ConvTranspose2d(128, 32, kernel_size=5, stride=2, padding=2, output_padding=1)\n",
    "        \n",
    "        self.deconv_bn4 = torch.nn.BatchNorm2d(32)\n",
    "        \n",
    "        self.deconv5 = torch.nn.ConvTranspose2d(64, 16, kernel_size=5, stride=2, padding=2, output_padding=1)\n",
    "        \n",
    "        self.deconv_bn5 = torch.nn.BatchNorm2d(16)\n",
    "        \n",
    "        self.deconv6 = torch.nn.ConvTranspose2d(32, n_class, kernel_size=5, stride=2, padding=2, output_padding=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        x = x.unsqueeze(1)\n",
    "\n",
    "        x = torch.log(x + 1e-8)\n",
    "        h1 = F.leaky_relu(self.conv_bn1(self.conv1(x)), 0.2)\n",
    "        h2 = F.leaky_relu(self.conv_bn2(self.conv2(h1)), 0.2)\n",
    "        h3 = F.leaky_relu(self.conv_bn3(self.conv3(h2)), 0.2)\n",
    "        h4 = F.leaky_relu(self.conv_bn4(self.conv4(h3)), 0.2)\n",
    "        h5 = F.leaky_relu(self.conv_bn5(self.conv5(h4)), 0.2)\n",
    "        h = F.leaky_relu(self.conv_bn6(self.conv6(h5)), 0.2)\n",
    "\n",
    "        h = self.dropout1(F.relu(self.deconv_bn1(self.deconv1(h))))\n",
    "        h = torch.cat((h, h5), dim=1)\n",
    "        h = self.dropout2(F.relu(self.deconv_bn2(self.deconv2(h))))\n",
    "        h = torch.cat((h, h4), dim=1)\n",
    "        h = self.dropout3(F.relu(self.deconv_bn3(self.deconv3(h))))\n",
    "        h = torch.cat((h, h3), dim=1)\n",
    "        h = F.relu(self.deconv_bn4(self.deconv4(h)))\n",
    "        h = torch.cat((h, h2), dim=1)\n",
    "        h = F.relu(self.deconv_bn5(self.deconv5(h)))\n",
    "        h = torch.cat((h, h1), dim=1)\n",
    "        h = F.softmax(self.deconv6(h), dim=1)\n",
    "        return h\n",
    "\n",
    "\n",
    "def padding(sound_stft):\n",
    "    frames = sound_stft.size(-1)\n",
    "    pad = (64 - frames % 64) % 64\n",
    "    if pad != 0:\n",
    "        l = pad // 2\n",
    "        r = pad - l\n",
    "        return F.pad(sound_stft, (l, r)), (l, r)\n",
    "    else:\n",
    "        return sound_stft, (0, 0)\n",
    "\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "def main():\n",
    "    torch.cuda.empty_cache()\n",
    "    torch.cuda.memory_summary(device=None, abbreviated=False)\n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "    torchaudio.USE_SOUNDFILE_LEGACY_INTERFACE = False\n",
    "    torchaudio.set_audio_backend(\"soundfile\")\n",
    "    os.mkdir(\"input_music\")\n",
    "    URL = str(input(\"Youtube link:\"))\n",
    "    os.system(\"youtube-dl -x --audio-format wav -o \\\"./input_music/%(title)s.%(ext)s\\\" \\\"\"+URL+\"\\\"\")\n",
    "    filename = os.listdir(\"input_music\")[0]\n",
    "    input_wav = \"input_music/\"+filename\n",
    "    os.mkdir(\"output_music\")\n",
    "    output_wav = \"./output_music/instrument_\"+filename\n",
    "    model_path = sys.argv[1]\n",
    "\n",
    "    device = torch.device('cpu')\n",
    "\n",
    "    with torch.no_grad():\n",
    "        sound, _ = torchaudio.load(input_wav)\n",
    "        sound = sound[[0], :].to(device)\n",
    "\n",
    "        window = torch.hann_window(2047, device=device)\n",
    "\n",
    "        sound_stft = torch.stft(sound, 2047, window=window)\n",
    "        sound_spec = sound_stft.pow(2).sum(-1).sqrt()\n",
    "        sound_spec, (left, right) = padding(sound_spec)\n",
    "\n",
    "        model = UNet(4)\n",
    "        model.load_state_dict(torch.load(model_path))\n",
    "        model.to(device)\n",
    "        model.eval()\n",
    "\n",
    "        right = sound_spec.size(2) - right\n",
    "        mask = model(sound_spec).squeeze(0)[:, :, left:right]\n",
    "        result = mask.unsqueeze(3) * sound_stft\n",
    "        result = torch.istft(result, 2047, window=window, length=sound.size(-1))\n",
    "        result = result.cpu().numpy()\n",
    "\n",
    "    sf.write(output_wav, result.T, 44100)\n",
    "    #x, _ = sf.read(input_wav)\n",
    "    #y, _ = sf.read(output_wav)\n",
    "    #y = y[:,[0,0]]\n",
    "    #print(bss_eval_sources(x, y))\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n",
    "\n",
    "print(\"Convert Successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "49247ac7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "546f9b2c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80531606",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
